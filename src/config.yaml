shared:
  n_peaks_per_sample: 600  # 600 peaks ~= 10 minutes of recording
  class_config: "all" # "all", "diab_v_comp", "comp_v_dpn"

model:
  n_peaks_per_sample: null # updated at runtime from shared config
  class_config: null # updated at runtime from shared config
  pos_encoding_type: "learned"  # "learned" or "sinusoidal"
  feature_dim: 128  # Transformer embedding size
  n_heads: 8  # Number of attention heads
  num_encoder_layers: 4  # Transformer encoder layers
  dim_feedforward: 512  # Feedforward dimension

  # Training Hyperparameters
  lr: 1e-3  # Learning rate
  weight_decay: 1e-5  # Regularization
  
  # Small constant added to denominators to prevent division by zero
  eps: 1.0e-8
  # Training hyperparameters
  dropout: 0.3    

  # populated automatically by trainer. set to null
  num_params: null

  # pooling method
  pooling: "mean"  # "mean" or "last"

  optim:
    lr: 0.001
  
  # class weights for only diabetes, complications, and dpn 
  class_weights: [1.0, 2.0, 5.0]

data:
  # path to the hrv data directory
  hrv_data_dir: ""  # This needs to be specified at runtime
  n_peaks_per_sample: null # updated at runtime from shared config
  class_config: null # updated at runtime from shared config
  
  # split
  slice_strategy: "sliding"  # "sliding" or "chunked"
  data_config: nabian

  min_hrv_threshold: 400
  max_hrv_threshold: 1300
  # data loader config params
  train:
    batch_size: 8
    num_workers: 4
    shuffle: true
    pin_memory: true
    drop_last: true

  val:
    batch_size: 8
    num_workers: 4
    shuffle: false
    pin_memory: true
    drop_last: true

trainer:
  epochs: 100
  n_batches_train: null  # if not null, will only train on these many batches
  n_batches_val: null    # if not null, will only validate on these many batches
  device: "cuda"
  log_every_n_steps: 50
  use_validation: true
  run_validation_every_n_steps: 500  # is used if use_validation is true
  use_lr_scheduler: false
  logs_dir: "logs"

wandb:
  entity: "ad-aspera"
  project: "diabeat"
  name: null
  logs_dir: "logs"


legacy_CNN_param:
  # Model architecture
  channels: [1, 32, 64, 128]  # [input, conv1, conv2, conv3]
  kernels: [15, 31, 61]  # [conv1, conv2, conv3]
  fc_dims: [64]  # Fully connected layer dimensions
  pool_size: 2
  stride: 1
  padding: "same"
  leaky_relu_slope: 0.01